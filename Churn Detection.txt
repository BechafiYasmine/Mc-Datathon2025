# ğŸ“¦ Importation des bibliothÃ¨ques nÃ©cessaires
import pandas as pd                 # Pour manipuler les donnÃ©es tabulaires (DataFrames)
import numpy as np                  # Pour les opÃ©rations mathÃ©matiques (non utilisÃ© ici mais souvent utile)
from sklearn.preprocessing import LabelEncoder  # Pour convertir les colonnes catÃ©gorielles en nombres
from lightgbm import LGBMClassifier # ModÃ¨le de classification rapide et puissant

# ğŸ“¥ Chargement des jeux de donnÃ©es d'entraÃ®nement et de test
train = pd.read_csv('/kaggle/input/churn-detection/train.csv')  # DonnÃ©es avec la colonne cible "Churn"
test = pd.read_csv('/kaggle/input/churn-detection/test.csv')    # DonnÃ©es sans la colonne cible

# ğŸ”– Sauvegarder les IDs pour les rÃ©utiliser dans la soumission finale
test_ids = test['id'].copy()

# ğŸ§  Conversion de la cible "Churn" de texte Ã  binaire : 'Yes' â†’ 1, 'No' â†’ 0
train['Churn'] = train['Churn'].map({'Yes': 1, 'No': 0})

# ğŸ”¢ Conversion de la colonne TotalCharges en numÃ©rique (peut contenir du texte vide ou invalide)
train['TotalCharges'] = pd.to_numeric(train['TotalCharges'], errors='coerce').fillna(0)
test['TotalCharges'] = pd.to_numeric(test['TotalCharges'], errors='coerce').fillna(0)

# ğŸ” Identification des colonnes de type "objet" (texte) Ã  encoder
cat_cols = train.select_dtypes(include='object').columns.tolist()

# ğŸ” Encodage des colonnes catÃ©gorielles en nombres avec LabelEncoder (mÃªme encodage pour train et test)
for col in cat_cols:
    le = LabelEncoder()
    combined = pd.concat([train[col], test[col]]).astype(str)  # Combinaison pour Ã©viter des valeurs inconnues
    le.fit(combined)                                           # Apprentissage des Ã©tiquettes
    train[col] = le.transform(train[col].astype(str))          # Transformation sur le train
    test[col] = le.transform(test[col].astype(str))            # Transformation sur le test

# ğŸ§® SÃ©paration des features (X) et de la cible (y) dans les donnÃ©es d'entraÃ®nement
X = train.drop(columns=["id", "Churn"])  # On enlÃ¨ve l'ID et la cible
y = train["Churn"]                       # La colonne cible
X_test = test.drop(columns=["id"])       # On enlÃ¨ve juste l'ID pour les prÃ©dictions

# âš™ï¸ CrÃ©ation et entraÃ®nement du modÃ¨le LightGBM
model = LGBMClassifier(
    random_state=42,       # Pour avoir les mÃªmes rÃ©sultats Ã  chaque exÃ©cution
    class_weight="balanced",  # GÃ¨re les classes dÃ©sÃ©quilibrÃ©es automatiquement
    n_estimators=100       # Nombre dâ€™arbres (plus = meilleur mais plus lent)
)
model.fit(X, y)  # EntraÃ®nement du modÃ¨le

# ğŸ“Š PrÃ©dictions : on rÃ©cupÃ¨re les probabilitÃ©s de la classe "1" (churn = Yes)
probs = model.predict_proba(X_test)[:, 1]  # ProbabilitÃ© que le client parte (churn)

# ğŸŸ¢ğŸŸ¥ Transformation en classe 1 (Yes) ou 0 (No) selon un seuil de 0.5
final_preds = (probs > 0.5).astype(int)

# ğŸ”„ Re-conversion des rÃ©sultats binaires en texte "Yes"/"No" pour respecter le format du concours
churn_labels = pd.Series(final_preds).map({1: "Yes", 0: "No"})

# ğŸ’¾ CrÃ©ation du fichier de soumission
submission = pd.DataFrame({
    "id": test_ids.astype(int),   # Les identifiants des clients
    "Churn": churn_labels         # Les prÃ©dictions sous forme de texte
})

# ğŸ’½ Export du fichier final au format CSV sans index
submission.to_csv("submission.csv", index=False)

# ğŸ§ª VÃ©rifications pour sâ€™assurer que tout est correct
print("ğŸ§ª test_ids sample:", test_ids[:5].values)         # Affiche les premiers IDs
print("ğŸ§ª final_preds sample:", final_preds[:5])         # Affiche les premiÃ¨res prÃ©dictions numÃ©riques
print("âœ… Lengths match:", len(test_ids) == len(final_preds))  # VÃ©rifie que les longueurs correspondent
[LightGBM] [Info] Number of positive: 1495, number of negative: 4139
[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002414 seconds.
You can set `force_row_wise=true` to remove the overhead.
And if memory is not enough, you can set `force_col_wise=true`.
[LightGBM] [Info] Total Bins 626
[LightGBM] [Info] Number of data points in the train set: 5634, number of used features: 19
[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000
[LightGBM] [Info] Start training from score 0.000000
ğŸ§ª test_ids sample: [0 1 2 3 4]
ğŸ§ª final_preds sample: [0 1 0 1 0]
âœ… Lengths match: True
print("ğŸ§ª test_ids sample:", test_ids[:5].values)
print("ğŸ§ª final_preds sample:", final_preds[:5])
print("âœ… Lengths match:", len(test_ids) == len(final_preds))
ğŸ§ª test_ids sample: [0 1 2 3 4]
ğŸ§ª final_preds sample: [0 1 0 1 0]
âœ… Lengths match: True
# âœ¨ **Challenge: Build Your Own Transformer from Scratch**

This is a minimal implementation of a decoder-only Transformer trained on a small poetic dataset.

## ğŸ§  What It Does

- Learns from a small paragraph of text  
- Predicts the next character one-by-one  
- Generates creative continuations from a prompt  

## ğŸ“ Files

- `transformer.py` - Model & training logic  
- `train.py` - Training script  
- `generate.py` - Sampling/generation script  
- `poem.txt` - Your training data  
- `model.pt` - Trained model checkpoint  

## ğŸš€ How to Run

### 1. Train the model

    python train.py

### 2. Generate text

    python generate.py

---



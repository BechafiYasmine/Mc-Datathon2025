{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":108136,"databundleVersionId":13101488,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T23:22:57.818388Z","iopub.execute_input":"2025-07-20T23:22:57.818657Z","iopub.status.idle":"2025-07-20T23:22:57.826134Z","shell.execute_reply.started":"2025-07-20T23:22:57.818637Z","shell.execute_reply":"2025-07-20T23:22:57.825347Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/phone-addiction-challenge/train.csv\n/kaggle/input/phone-addiction-challenge/test.csv\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, QuantileTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.linear_model import ElasticNet\n\n# Load data\ntrain = pd.read_csv('/kaggle/input/phone-addiction-challenge/train.csv')\ntest = pd.read_csv('/kaggle/input/phone-addiction-challenge/test.csv')\n\n# Advanced feature engineering\nfor df in [train, test]:\n    # Time-based ratios (log-scaled)\n    df['Social_Edu_Ratio'] = np.log1p(df['Time_on_Social_Media']) / np.log1p(df['Time_on_Education'] + 0.01)\n    df['Gaming_Usage_Ratio'] = np.log1p(df['Time_on_Gaming'] + 1) / np.log1p(df['Daily_Usage_Hours'] + 1)\n    \n    # Behavioral interactions\n    df['Mental_Health_Index'] = 0.5*df['Anxiety_Level'] + 0.5*df['Depression_Level']\n    df['Parental_Sleep_Effect'] = df['Parental_Control'] * np.sqrt(df['Sleep_Hours'])\n    \n    # Productivity metrics\n    df['Academic_Efficiency'] = df['Academic_Performance'] / (df['Daily_Usage_Hours'] + 1)\n    df['Social_Productivity'] = df['Social_Interactions'] / (df['Time_on_Social_Media'] + 0.1)\n\n# Define feature types\ncategorical_cols = ['Gender', 'Location', 'School_Grade', 'Phone_Usage_Purpose']\nnumerical_cols = [col for col in train.columns \n                 if col not in ['id', 'Name', 'Addiction_Level'] + categorical_cols]\n\n# Enhanced preprocessing (updated to remove warnings)\npreprocessor = ColumnTransformer([\n    ('num', Pipeline([\n        ('quantile', QuantileTransformer(output_distribution='normal')),\n        ('scaler', StandardScaler())\n    ]), numerical_cols),\n    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n], remainder='drop')\n\n# Optimized ensemble models\nbase_models = [\n    ('xgb', XGBRegressor(\n        n_estimators=1200,\n        learning_rate=0.008,\n        max_depth=4,\n        subsample=0.75,\n        colsample_bytree=0.65,\n        gamma=0.2,\n        random_state=42,\n        tree_method='hist'\n    )),\n    ('lgbm', LGBMRegressor(\n        n_estimators=1800,\n        learning_rate=0.006,\n        num_leaves=25,\n        feature_fraction=0.65,\n        bagging_fraction=0.8,\n        bagging_freq=6,\n        min_data_in_leaf=20,\n        random_state=42,\n        verbose=-1\n    ))\n]\n\n# Meta-learner\nfinal_estimator = ElasticNet(\n    alpha=0.0005, \n    l1_ratio=0.75, \n    random_state=42,\n    max_iter=2000\n)\n\n# Full pipeline\nmodel = Pipeline([\n    ('preprocessor', preprocessor),\n    ('ensemble', StackingRegressor(\n        estimators=base_models,\n        final_estimator=final_estimator,\n        cv=7,\n        n_jobs=-1,\n        passthrough=True\n    ))\n])\n\n# Train with cross-validation\nX = train.drop(['id', 'Name', 'Addiction_Level'], axis=1)\ny = train['Addiction_Level']\n\nscores = -cross_val_score(model, X, y, \n                        cv=7, \n                        scoring='neg_mean_squared_error',\n                        n_jobs=-1)\nprint(f\"Cross-validated RMSE: {np.mean(np.sqrt(scores)):.5f} ± {np.std(np.sqrt(scores)):.5f}\")\n\n# Final training\nmodel.fit(X, y)\n\n# Generate predictions with clipping\ntest_preds = model.predict(test.drop(['id', 'Name'], axis=1))\ntest_preds = np.clip(test_preds, \n                    train['Addiction_Level'].min() * 0.95, \n                    train['Addiction_Level'].max() * 1.05)\n\n# Create submission\nsubmission = pd.DataFrame({\n    'id': test['id'],\n    'Addiction_Level': test_preds\n})\nsubmission.to_csv('submission.csv', index=False)\n\n# Download link\nfrom IPython.display import FileLink\nprint(\"✅ Submission ready! Click below to download:\")\nFileLink('submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T23:22:57.827486Z","iopub.execute_input":"2025-07-20T23:22:57.827748Z","iopub.status.idle":"2025-07-20T23:26:43.529621Z","shell.execute_reply.started":"2025-07-20T23:22:57.827727Z","shell.execute_reply":"2025-07-20T23:26:43.528909Z"}},"outputs":[{"name":"stdout","text":"Cross-validated RMSE: 0.33886 ± 0.01455\n✅ Submission ready! Click below to download:\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submission.csv","text/html":"<a href='submission.csv' target='_blank'>submission.csv</a><br>"},"metadata":{}}],"execution_count":5}]}